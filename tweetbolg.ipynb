{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "df=pd.read_csv('C:/Users/deCaY/Desktop/final_tweet_collection.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import itertools\n",
    "\n",
    "def tweet_cleaner(df):\n",
    "    \n",
    "    for i in range(0,len(df)):\n",
    "        txt = df.loc[i,'tweet_text']\n",
    "        x = re.sub( \"[#./:&;’“]+[a-zA-z0-9-]*\", \"\", txt)                #Remove any punctuation marks and hashtags\n",
    "        x = re.sub( \"https?\", \"\", x)                                                #Remove URLs\n",
    "        x = re.sub(\"/\\b\\d[^th][^nd][^st][^rd][a-zA-z]+\", \"\", x)    #Remove typos beginning with numbers\n",
    "        x=\" \".join(x.split())                                                          #Remove unnecessary blank spaces\n",
    "        df.loc[i,'tweet_text']=x\n",
    "    \n",
    "    all_tweets_no_urls = df['tweet_text']\n",
    "    \n",
    "    #Tokenize the string(can also be performed using nltk.tokenize)\n",
    "\n",
    "\n",
    "    words_in_tweet = [tweet.lower().split() for tweet in all_tweets_no_urls]\n",
    "    \n",
    "    #Stopwords are words which do not add much meaning to a sentence\n",
    "    #They can safely be ignored without sacrificing the meaning of the sentence\n",
    "    #These add no value to the analysis and removing them will improve processsing time and accuracy of the classifier\n",
    "\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['u','ur','i',\"i’m\",\"i’ve\"])\n",
    "    \n",
    "    tweets_nsw = [[word for word in tweet_words if not word in stop_words]\n",
    "              for tweet_words in words_in_tweet]\n",
    "    \n",
    "    #itertools.chain is a function that takes a series of iterables and returns one iterable\n",
    "    #Create a single list of individual words\n",
    "\n",
    "\n",
    "    all_words_nsw = list(itertools.chain(*tweets_nsw))\n",
    "\n",
    "    #Some of the tweets contain phrases in Hindi, Spanish and other languages\n",
    "    #Remove all non-English words\n",
    "\n",
    "\n",
    "    words = set(nltk.corpus.words.words())\n",
    "\n",
    "    eng_only=[]\n",
    "    for i in all_words_nsw:\n",
    "        if i.lower() in words:\n",
    "            eng_only.append(i)\n",
    "    \n",
    "    #Lemmatization is the process of normalizing words into their base or root form\n",
    "\n",
    "\n",
    "    cleaned=[]   \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for word in eng_only:\n",
    "        cleaned.append(lemmatizer.lemmatize(word))\n",
    "    \n",
    "    return(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweets = df[df['sentiments'] == 'Positive']\n",
    "\n",
    "positive_tweets.reset_index(inplace=True)\n",
    "\n",
    "cleaned_positive_tweets = tweet_cleaner(positive_tweets)\n",
    "\n",
    "\n",
    "negative_tweets = df[df['sentiments'] == 'Negative']\n",
    "\n",
    "negative_tweets.reset_index(inplace=True)\n",
    "\n",
    "cleaned_negative_tweets = tweet_cleaner(negative_tweets)\n",
    "\n",
    "\n",
    "miscellaneous_tweets = df[df['sentiments'] == 'Miscellaneous']\n",
    "\n",
    "miscellaneous_tweets.reset_index(inplace=True)\n",
    "\n",
    "cleaned_miscellaneous_tweets = tweet_cleaner(miscellaneous_tweets)\n",
    "\n",
    "\n",
    "all_cleaned_tweets = cleaned_positive_tweets + cleaned_negative_tweets + cleaned_miscellaneous_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(all_cleaned_tweets)\n",
    "X = cv.transform(all_cleaned_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.7126373626373627\n",
      "Accuracy for C=0.05: 0.7159340659340659\n",
      "Accuracy for C=0.25: 0.7236263736263736\n",
      "Accuracy for C=0.5: 0.7236263736263736\n",
      "Accuracy for C=1: 0.7230769230769231\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "target=[]\n",
    "\n",
    "for i in range(len(all_cleaned_tweets)):\n",
    "    if (i<len(cleaned_positive_tweets)):\n",
    "        target.append(2)\n",
    "    elif (i>len(cleaned_positive_tweets) & i<len(cleaned_positive_tweets)+len(cleaned_negative_tweets)):\n",
    "        target.append(1)\n",
    "    else :\n",
    "        target.append(0)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, target, train_size = 0.75, random_state=0)\n",
    "\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\n",
    "\n",
    "    lr = LogisticRegression(C=c, solver='lbfgs', multi_class='auto', max_iter=1000, random_state=0)\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    print (\"Accuracy for C=%s: %s\"% (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
